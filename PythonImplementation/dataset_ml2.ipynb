{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNA\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import SVG, display\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import difflib\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# from helper import print_moves\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "from pretty_print_path import print_moves\n",
    "import findpath_librna\n",
    "import findpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3451 train examples\n"
     ]
    }
   ],
   "source": [
    "input_file = \"dataset_105_train.csv\"\n",
    "input_file2 = \"dataset_105_vec_train.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(input_file, index_col=0)\n",
    "# dataframe['target'] = np.where(dataframe[\"3\"]==1, 1, 0)\n",
    "dataframe = dataframe.drop(labels=\"s\", axis=1)\n",
    "dataframe = dataframe.drop(labels=\"i\", axis=1)\n",
    "dataframe = dataframe.drop(labels=\"j\", axis=1)\n",
    "# dataframe = dataframe.drop(labels=\"found\", axis=1)\n",
    "\n",
    "# dataframe\n",
    "\n",
    "vec_dataframe = pd.read_csv(input_file2, index_col=0)\n",
    "# vec_dataframe\n",
    "dataframe = pd.concat([dataframe, vec_dataframe], axis=1)\n",
    "\n",
    "\n",
    "# new\n",
    "train, _ = train_test_split(dataframe, test_size=0.3)\n",
    "print(len(train), 'train examples')\n",
    "\n",
    "# old\n",
    "# train, test = train_test_split(dataframe, test_size=0.2)\n",
    "# train, val = train_test_split(train, test_size=0.2)\n",
    "# print(len(train), 'train examples')\n",
    "# print(len(val), 'validation examples')\n",
    "# print(len(test), 'test examples')\n",
    "\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3451 train examples\n",
      "1381 validation examples\n",
      "2070 test examples\n"
     ]
    }
   ],
   "source": [
    "input_file = \"dataset_105_test.csv\"\n",
    "input_file2 = \"dataset_105_vec_test.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(input_file, index_col=0)\n",
    "# dataframe['target'] = np.where(dataframe[\"3\"]==1, 1, 0)\n",
    "dataframe = dataframe.drop(labels=\"s\", axis=1)\n",
    "dataframe = dataframe.drop(labels=\"i\", axis=1)\n",
    "dataframe = dataframe.drop(labels=\"j\", axis=1)\n",
    "# dataframe = dataframe.drop(labels=\"found\", axis=1)\n",
    "\n",
    "# dataframe\n",
    "\n",
    "vec_dataframe = pd.read_csv(input_file2, index_col=0)\n",
    "# vec_dataframe\n",
    "dataframe = pd.concat([dataframe, vec_dataframe], axis=1)\n",
    "\n",
    "\n",
    "_, test = train_test_split(dataframe, test_size=0.2)\n",
    "test, val = train_test_split(train, test_size=0.4)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# ## Understand the input pipeline\n",
    "# # Now that we have created the input pipeline, let's call it to see the format of the data it returns. We have used a small batch size to keep the output readable.\n",
    "\n",
    "# for feature_batch, label_batch in train_ds.take(1):\n",
    "#   print('Every feature:', list(feature_batch.keys()))\n",
    "#   print('A batch of ages:', feature_batch['4'])\n",
    "#   print('A batch of targets:', label_batch )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_ds))[0]\n",
    "\n",
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def demo(feature_column):\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  # print(feature_layer(example_batch).numpy())\n",
    "\n",
    "# # numeric columns\n",
    "photo_count = feature_column.numeric_column('4')\n",
    "demo(photo_count)\n",
    "photo_count2 = feature_column.numeric_column('5')\n",
    "\n",
    "crossed_feature = feature_column.crossed_column(['4', '1'], hash_bucket_size=10)\n",
    "demo(feature_column.indicator_column(crossed_feature))\n",
    "\n",
    "# # column 7 is a catigorical column\n",
    "# animal_type = feature_column.categorical_column_with_vocabulary_list(\n",
    "#       '7', [0, 1])\n",
    "# animal_type_one_hot = feature_column.indicator_column(animal_type)\n",
    "# demo(animal_type_one_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which columns to use\n",
    "We have seen how to use several types of feature columns. Now we will use them to train a model. The goal of this tutorial is to show you the complete code (e.g. mechanics) needed to work with feature columns. We have selected a few columns to train our model below arbitrarily.\n",
    "\n",
    "Key point: If your aim is to build an accurate model, try a larger dataset of your own, and think carefully about which features are the most meaningful to include, and how they should be represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# ijd\tthisclose\tlastclose\tcd\ten_pos\n",
    "\n",
    "# numeric cols\n",
    "for header in ['ijd',\t'thisclose',\t'lastclose',\t'en_pos', 'i_shift',\t'j_shift',\t'insert_or_delete']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# numeric cols\n",
    "for header in ['0',\t'1',\t'2',\t'3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# categoriacal indicator_columns\n",
    "indicator_column_names = ['cd']\n",
    "for col_name in indicator_column_names:\n",
    "  categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "      col_name, dataframe[col_name].unique())\n",
    "  indicator_column = feature_column.indicator_column(categorical_column)\n",
    "  feature_columns.append(indicator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use lowest energy as indicator\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['en_pos']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='en_pos', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature layer\n",
    "Now that we have defined our feature columns, we will use a [DenseFeatures](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/DenseFeatures) layer to input them to our Keras model.\n",
    "\n",
    "Earlier, we used a small batch size to demonstrate how feature columns worked. We create a new input pipeline with a larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "# batch_size = 32\n",
    "batch_size = 64\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'ijd': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'thisclose': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'lastclose': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'cd': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'en_pos': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'i_shift': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'j_shift': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'insert_or_delete': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'balance': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, '0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, '1': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, '2': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, '3': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, '4': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, '5': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, '6': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, '7': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, '8': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, '9': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, '10': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, '11': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, '12': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, '13': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, '14': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, '15': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, '16': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, '17': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, '18': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, '19': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'ijd': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'thisclose': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'lastclose': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'cd': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'en_pos': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'i_shift': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'j_shift': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'insert_or_delete': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'balance': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, '0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, '1': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, '2': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, '3': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, '4': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, '5': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, '6': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, '7': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, '8': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, '9': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, '10': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, '11': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, '12': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, '13': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, '14': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, '15': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, '16': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, '17': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, '18': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, '19': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.6447WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'ijd': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'thisclose': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'lastclose': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'cd': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'en_pos': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'i_shift': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'j_shift': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'insert_or_delete': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'balance': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, '0': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, '1': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, '2': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, '3': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, '4': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, '5': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, '6': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, '7': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, '8': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, '9': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, '10': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, '11': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, '12': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, '13': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, '14': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, '15': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, '16': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, '17': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, '18': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, '19': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "54/54 [==============================] - 2s 17ms/step - loss: 0.6025 - accuracy: 0.6447 - val_loss: 0.5835 - val_accuracy: 0.6445\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5853 - accuracy: 0.6447 - val_loss: 0.5767 - val_accuracy: 0.6445\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5850 - accuracy: 0.6775 - val_loss: 0.5744 - val_accuracy: 0.6959\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7004 - val_loss: 0.5761 - val_accuracy: 0.7075\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5813 - accuracy: 0.7010 - val_loss: 0.5717 - val_accuracy: 0.7024\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5787 - accuracy: 0.7015 - val_loss: 0.5768 - val_accuracy: 0.7053\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5806 - accuracy: 0.7039 - val_loss: 0.5746 - val_accuracy: 0.6980\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5819 - accuracy: 0.7044 - val_loss: 0.5715 - val_accuracy: 0.6973\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5800 - accuracy: 0.7007 - val_loss: 0.5705 - val_accuracy: 0.7031\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5791 - accuracy: 0.7036 - val_loss: 0.5713 - val_accuracy: 0.7089\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5768 - accuracy: 0.7012 - val_loss: 0.5698 - val_accuracy: 0.7024\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 1s 8ms/step - loss: 0.5795 - accuracy: 0.7012 - val_loss: 0.5697 - val_accuracy: 0.7017\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 1s 8ms/step - loss: 0.5772 - accuracy: 0.7004 - val_loss: 0.5696 - val_accuracy: 0.7024\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5797 - accuracy: 0.7015 - val_loss: 0.5702 - val_accuracy: 0.6980\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5771 - accuracy: 0.7007 - val_loss: 0.5702 - val_accuracy: 0.7024\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5774 - accuracy: 0.7027 - val_loss: 0.5701 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5776 - accuracy: 0.6981 - val_loss: 0.5693 - val_accuracy: 0.7009\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5790 - accuracy: 0.7004 - val_loss: 0.5695 - val_accuracy: 0.7002\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.5770 - accuracy: 0.6978 - val_loss: 0.5696 - val_accuracy: 0.6966\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.5777 - accuracy: 0.7012 - val_loss: 0.5764 - val_accuracy: 0.7009\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.5800 - accuracy: 0.6986 - val_loss: 0.5733 - val_accuracy: 0.7038\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.5780 - accuracy: 0.7007 - val_loss: 0.5708 - val_accuracy: 0.6966\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5798 - accuracy: 0.6995 - val_loss: 0.5703 - val_accuracy: 0.7024\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.5775 - accuracy: 0.7033 - val_loss: 0.5696 - val_accuracy: 0.6959\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.5773 - accuracy: 0.6978 - val_loss: 0.5695 - val_accuracy: 0.6973\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5811 - accuracy: 0.7010 - val_loss: 0.5731 - val_accuracy: 0.7009\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.6998 - val_loss: 0.5695 - val_accuracy: 0.6966\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5762 - accuracy: 0.6986 - val_loss: 0.5711 - val_accuracy: 0.6966\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5781 - accuracy: 0.6986 - val_loss: 0.5706 - val_accuracy: 0.6951\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5779 - accuracy: 0.6992 - val_loss: 0.5694 - val_accuracy: 0.6959\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5776 - accuracy: 0.6992 - val_loss: 0.5704 - val_accuracy: 0.6959\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5777 - accuracy: 0.7001 - val_loss: 0.5695 - val_accuracy: 0.6966\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.6986 - val_loss: 0.5711 - val_accuracy: 0.7009\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5790 - accuracy: 0.7001 - val_loss: 0.5705 - val_accuracy: 0.6959\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7007 - val_loss: 0.5696 - val_accuracy: 0.6959\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.6989 - val_loss: 0.5705 - val_accuracy: 0.6980\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.6983 - val_loss: 0.5705 - val_accuracy: 0.7017\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5763 - accuracy: 0.7001 - val_loss: 0.5697 - val_accuracy: 0.6959\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5771 - accuracy: 0.6983 - val_loss: 0.5713 - val_accuracy: 0.6930\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5777 - accuracy: 0.6972 - val_loss: 0.5718 - val_accuracy: 0.6959\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5783 - accuracy: 0.6989 - val_loss: 0.5692 - val_accuracy: 0.6966\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.6986 - val_loss: 0.5691 - val_accuracy: 0.6959\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5773 - accuracy: 0.6983 - val_loss: 0.5701 - val_accuracy: 0.6944\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 1s 8ms/step - loss: 0.5775 - accuracy: 0.6992 - val_loss: 0.5694 - val_accuracy: 0.6959\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5773 - accuracy: 0.6983 - val_loss: 0.5697 - val_accuracy: 0.6937\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.6989 - val_loss: 0.5773 - val_accuracy: 0.6944\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5786 - accuracy: 0.6983 - val_loss: 0.5693 - val_accuracy: 0.6959\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5757 - accuracy: 0.7001 - val_loss: 0.5697 - val_accuracy: 0.6966\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5762 - accuracy: 0.6983 - val_loss: 0.5724 - val_accuracy: 0.7024\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5783 - accuracy: 0.6992 - val_loss: 0.5691 - val_accuracy: 0.6973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c30370490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  # layers.Dense(128, activation='relu'),\n",
    "  # layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8602\n",
      "Accuracy 0.8601823449134827\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8480\n",
      "Accuracy 0.848024308681488\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 964us/step - loss: 0.5752 - accuracy: 0.7214\n",
      "Accuracy 0.7213779091835022\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31/31 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.7335\n",
    "# Accuracy 0.7335359454154968\n",
    "\n",
    "# 31/31 [==============================] - 0s 862us/step - loss: 0.5798 - accuracy: 0.6950\n",
    "# Accuracy 0.695035457611084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# !mkdir -p saved_model\n",
    "# model.save('saved_model/my_model')\n",
    "\n",
    "# from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "\n",
    "# filepath = './saved_model'\n",
    "# save_model(model, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morgan & Higgs: Findpath with SW 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True) # no scientific notation\n",
    "\n",
    "# import feature_generation\n",
    "from features import ij_distance, new_move_dist, plt_moves, config_distance, balance_in_all_things, return_shift_moves\n",
    "\n",
    "from process_features import fp_call, find_moves, process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = \"dataset_100.csv\"\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# sequence, s1, s2 = df.loc[0]\n",
    "\n",
    "\n",
    "# search_width_multiplier = 4\n",
    "# fp = findpath.findpath_single(sequence, s1, s2, search_width_multiplier=search_width_multiplier, mp=True)\n",
    "# result = fp.get_en()/100.0\n",
    "# path = fp.get_path()\n",
    "\n",
    "# s = s1\n",
    "# pt2 = list(RNA.ptable(s2))\n",
    "# fc = RNA.fold_compound(sequence)\n",
    "\n",
    "\n",
    "# def find_moves(s_ptable, t_ptable):\n",
    "#     \"\"\"\n",
    "#     generator function, yields possible structures 1 move away\n",
    "#     from the original structure by finding fitting i and j with\n",
    "#     RNA pair and loop tables\n",
    "#     s_ptable: current ptable\n",
    "#     t_ptable: s2 end ptable\n",
    "#     \"\"\"\n",
    "#     # loop table\n",
    "#     ls = RNA.loopidx_from_ptable(s_ptable)\n",
    "#     for i in range(len(s_ptable)):\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "#         if s_ptable[i] == 0 and t_ptable[i] > i:\n",
    "#             j = t_ptable[i]\n",
    "#             # found j has to be empty and currently on the same loop as i\n",
    "#             if s_ptable[j] == 0 and ls[i] == ls[j]:\n",
    "#                 yield i, j\n",
    "#         # test for bp removal: i has to be paired with a different j in s2\n",
    "#         j = s_ptable[i]\n",
    "#         # dont remove things which are present in s2\n",
    "#         if s_ptable[i] > i and s_ptable[i] != s_ptable[j] and\\\n",
    "#                 s_ptable[i] != t_ptable[i] and s_ptable[j] != t_ptable[j]:\n",
    "#             yield -i, -j\n",
    "\n",
    "\n",
    "# def fp_call(sequence, s1, s2, search_width_multiplier = 20):    \n",
    "#     fp = findpath.findpath_single(sequence, s1, s2, search_width_multiplier=search_width_multiplier, mp=True)\n",
    "#     result = fp.get_en()/100.0\n",
    "#     path = fp.get_path()\n",
    "#     # return result, path\n",
    "#     return result, path\n",
    "\n",
    "\n",
    "# def ij_distance(last_move, this_move, ij_moves):\n",
    "#     # how far is the last move away from the current move.\n",
    "#     # it is likely, that the next move is close to the last one\n",
    "#     # there are better distance metrices probably...\n",
    "\n",
    "#     # ij move list is supposed to be sorted, find indices\n",
    "    \n",
    "#     ijmoves = ij_moves + [last_move]\n",
    "#     ijmoves.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "#     pos_old = ijmoves.index(last_move)\n",
    "#     pos_new = ijmoves.index(this_move)\n",
    "\n",
    "#     distance = abs(pos_old-pos_new)/len(ijmoves)\n",
    "    \n",
    "    \n",
    "#     # moves left in vicinity out of total moves\n",
    "    \n",
    "#     thisi, thisj = this_move\n",
    "#     lasti, lastj = last_move\n",
    "#     thisclose = 0\n",
    "#     lastclose = 0\n",
    "\n",
    "#     for i, j in ij_moves:\n",
    "#         if (abs(i-thisi) < 5) and (abs(j-thisj) < 5):\n",
    "#             thisclose += 1\n",
    "#         if (abs(i-lasti) < 5) and (abs(j-lastj) < 5):\n",
    "#             lastclose += 1\n",
    "    \n",
    "\n",
    "#     thisclose /= len(ij_moves)\n",
    "#     lastclose /= len(ij_moves)\n",
    "\n",
    "#     # print (\"thisclose\", thisclose, lastclose, distance)\n",
    "#     return distance, thisclose, lastclose\n",
    "\n",
    "#     print (distance)\n",
    "\n",
    "# # sample call\n",
    "# ij_moves = [(3, 62), (4, 61), (6, 60), (7, 59), (9, 57), (10, 56), (11, 55), (12, 54), (15, 52), (16, 51), (17, 50), (18, 39), (19, 38), (20, 36), (21, 35), (22, 34), (23, 33), (24, 32), (42, 49), (43, 48), (64, 99)]\n",
    "# last_move = (2, 63)\n",
    "# this_move = (6, 60)\n",
    "# ij_distance(last_move, this_move, ij_moves)\n",
    "\n",
    "# # \n",
    "\n",
    "# def config_distance(pt, move):\n",
    "#     \"\"\"\n",
    "#     are we extending / removing the outside/inside layer of a loop or adding something in the middle?\n",
    "#     \"\"\"\n",
    "#     i = move[0]\n",
    "#     j = move[1]\n",
    "#     points = 0\n",
    "\n",
    "#     # if we're extending from outside to inside, the position i+1 and j-1 should be ideally unpaired\n",
    "#     # inside to outside: i-1 and j+1 should be ideally unpaired\n",
    "\n",
    "#     if i>0:\n",
    "#         # print (\"add\") \n",
    "#         # outside/inside paired?        \n",
    "#         if j+1 < pt[0] and i-1 > 0: # outside - boundary check\n",
    "#             if pt[i-1] == j+1:\n",
    "#                 points += 1\n",
    "#         if pt[i+1] == j-1:\n",
    "#             points += 1\n",
    "#     if i<0:\n",
    "#         # print (\"del\")\n",
    "#         i, j = -i, -j\n",
    "#         # outside/inside paired?\n",
    "#         if j+1 < pt[0] and i-1 > 0: # outside - boundary check\n",
    "#             if pt[i-1] == j+1:\n",
    "#                 points += 1\n",
    "#         if pt[i+1] == j-1:\n",
    "#             points += 1\n",
    "#         elif pt[i+1] == 0 and pt[j-1] == 0:\n",
    "#             pass\n",
    "\n",
    "#     if points == 2:\n",
    "#         points = 0\n",
    "#     return points\n",
    "\n",
    "\n",
    "# s = s1\n",
    "# lasts = s\n",
    "# lasti = None\n",
    "# lastj = None\n",
    "\n",
    "# for e, (a,b, en) in enumerate(path):\n",
    "#     if (a,b) == (0,0):\n",
    "#         continue  \n",
    "\n",
    "#     # check where we can go, compare with our best move. \n",
    "#     pt = list(RNA.ptable(s))\n",
    "\n",
    "#     # check available moves, save them, sort them    \n",
    "#     avail_moves = []\n",
    "#     ij_moves = []\n",
    "#     found_pos = None\n",
    "\n",
    "#     for pos, (i,j) in enumerate(find_moves(pt, pt2)):    \n",
    "#         next_en = fc.eval_move_pt(pt, i, j)\n",
    "#         # mark where we found our move\n",
    "#         found = (i,j) == (a,b)\n",
    "#         avail_moves.append((i, j, next_en, found))\n",
    "#         ij_moves.append((abs(i),abs(j)))\n",
    "\n",
    "#     # sort moves independent of delete insert moves\n",
    "\n",
    "#     ij_moves.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "\n",
    "#     avail_moves.sort(key=lambda x: x[2])\n",
    "#     found_list = [x[3] for x in avail_moves]\n",
    "#     en_list = np.array([[x[2] for x in avail_moves]])\n",
    "#     en_list_scaled = min_max_scaler.fit_transform(en_list.T).T[0]\n",
    "    \n",
    "\n",
    "#     # find where our move is after sorting\n",
    "#     found_pos = found_list.index(True)\n",
    "#     rel_pos = found_pos * 1.0 / len(found_list)\n",
    "\n",
    "#     # print (e, a,b, 'found at pos:', found_pos, 'of', len(avail_moves), ':',  1-rel_pos)\n",
    "#     # print (avail_moves, a, b)\n",
    "\n",
    "#     # if s != lasts:\n",
    "#         # print (\"---\") \n",
    "#         # print (s)\n",
    "#         # print (\"---\") \n",
    "\n",
    "#     # for every move we take we have to run a new findpath, see if this move will yield the ideal result\n",
    "    \n",
    "#     for pos, (i,j, en, found) in enumerate(avail_moves):\n",
    "#         if i > 0:\n",
    "#             snew = s[:i-1] + \"(\" + s[i:j-1] + \")\" + s[j:]\n",
    "#         if i < 0:\n",
    "#             snew = s[:-i-1] + \".\" + s[-i:-j-1] + \".\" + s[-j:]\n",
    "#         ptnew = list(RNA.ptable(snew))\n",
    "\n",
    "#         result_new, path = fp_call(sequence, snew, s2)\n",
    "\n",
    "#         if result_new <= result:\n",
    "#             pos_result = 1\n",
    "#         else:\n",
    "#             pos_result = 0\n",
    "\n",
    "#         if found: found = \"<-- taken\"\n",
    "#         else: found = \"\"\n",
    "\n",
    "#         this_move = (abs(i), abs(j))\n",
    "#         last_move = (lasti, lastj)\n",
    "\n",
    "#         if lasti:\n",
    "#             # print (this_move, last_move, ij_moves)\n",
    "#             ijd, thisclose, lastclose = ij_distance(last_move, this_move, ij_moves)\n",
    "#         else:\n",
    "#             ijd, thisclose, lastclose = 0, 0, 0\n",
    "\n",
    "#         cd = config_distance(pt, this_move)\n",
    "\n",
    "#         if lasti:\n",
    "#             print (f' {snew[0:20]}, {i}, {j}, {result_new}/{pos_result}: {ijd:2.2f}, {thisclose:2.2f}, {lastclose:2.2f}, {cd}, {en}, {en_list_scaled[pos]:2.2f} {found}')\n",
    "\n",
    "#             sample = 1, ijd, thisclose, lastclose, cd, en_list_scaled[pos], 1\n",
    "#             sample_test_ds = sample_to_dataset(sample, test)\n",
    "#             result_predictor = model.predict(sample_test_ds)[0][0]\n",
    "\n",
    "#             print (f' {1}, {ijd:2.2f}, {thisclose:2.2f}, {lastclose:2.2f}, {cd}, {en_list_scaled[pos]:2.2f}, 1: prediction: {result_predictor}')\n",
    "\n",
    "\n",
    "\n",
    "#     # if e==63:\n",
    "#     #     print (avail_moves)\n",
    "\n",
    "#     # update s for the next iteration\n",
    "    \n",
    "#     lasts = s\n",
    "#     lasti = abs(a)\n",
    "#     lastj = abs(b)\n",
    "#     if a > 0:\n",
    "#         s = s[:a-1] + \"(\" + s[a:b-1] + \")\" + s[b:]\n",
    "#     if a < 0:\n",
    "#         s = s[:-a-1] + \".\" + s[-a:-b-1] + \".\" + s[-b:]\n",
    "\n",
    "#     if e>1: \n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-15.837],\n",
       "       [ 11.275],\n",
       "       [  3.746],\n",
       "       ...,\n",
       "       [ 24.054],\n",
       "       [ -6.914],\n",
       "       [ -3.432]], dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A few random samples\n",
    "\n",
    "# Generate predictions for samples\n",
    "predictions = model.predict(test_ds)\n",
    "predictions\n",
    "# sample_test\n",
    "# test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.443512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-32.443512]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A utility method to create a tf.data from a dictionary\n",
    "def dict_to_dataset(inputdict, labels, shuffle=True, batch_size=32):\n",
    "  # dataframe = dataframe.copy()\n",
    "  # labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((inputdict, labels))\n",
    "  # ds = tf.data.Dataset.from_tensor_slices([45240,  0.5,  0.142857,  0.047619,  0,  0.930233,       0])\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))  \n",
    "  print ('ds', ds)\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "def sample_to_dataset(sample, test):\n",
    "\n",
    "  sample_test = test.iloc[0:1].copy()\n",
    "  row0 = sample_test.index[0]\n",
    "\n",
    "  # print (sample_test)\n",
    "\n",
    "  for key, value in sample.items():\n",
    "    sample_test.at[row0, key] = value\n",
    "# \n",
    "  # print (sample_test)\n",
    "\n",
    "  # print (i, j)\n",
    "  # sample_test.at[row0 ,'Unnamed: 0'] = 2 # irrelevant\n",
    "  # sample_test.at[row0 ,'4'] = sample[1]\n",
    "  # sample_test.at[row0 ,'5'] = sample[2]\n",
    "  # sample_test.at[row0 ,'6'] = sample[3]\n",
    "  # sample_test.at[row0 ,'7'] = sample[4]\n",
    "  # sample_test.at[row0 ,'8'] = sample[5]\n",
    "  # sample_test.at[row0 ,'target'] = 2 # irrelevant\n",
    "\n",
    "  sample_test_ds = df_to_dataset(sample_test, shuffle=False, batch_size=batch_size)\n",
    "  return sample_test_ds\n",
    "\n",
    "\n",
    "sample = { \"target\": 0,\n",
    "           \"ijd\":    1,\n",
    "           \"thisclose\": 0.2,\n",
    "           \"lastclose\": 0.5,\n",
    "           \"cd\":        0.5,\n",
    "           \"en_pos\":    0.7,\n",
    "           \"i_shift\":   1, \n",
    "           \"j_shift\":   1,\n",
    "           \"insert_or_delete\": 0,\n",
    "           \"balance\":   1,\n",
    "           \"19\": 0.5\n",
    "}\n",
    "\n",
    "# sample = [1, 0.82, 0.44, 0.24, 1, 0.05, 1]\n",
    "# sample = 1, 0.36, 0.29, 0.14, 1, 0.00, 1\n",
    "sample_test_ds = sample_to_dataset(sample, test)\n",
    "\n",
    "# print (sample_test_ds)\n",
    "\n",
    "result_predictor = model.predict(sample_test_ds)[0][0]\n",
    "print (result_predictor)\n",
    "\n",
    "\n",
    "predictions = model.predict(sample_test_ds)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGGUAUCGGGGCCCUCCAACCACCAAGCGGCAGGAUUGCCACGCUACGGUUGAUGGCGUUUAGUAGUUGAUACGUCAAGACGUCGAAACGCUCAGUAGC\n",
      "........((.(((.((.((((....(((((((....))))..)))..)))))).))).)).(((.(((...((((....))))...)))))).......\n",
      "..(((.....((........)))))..(.((((....)))).)(((((...((.((((((((....((....))....))))))))...))....)))))\n",
      "ACGGUAUCGGGGCCCUCCAACCACCAAGCGGCAGGAUUGCCACGCUACGGUUGAUGGCGUUUAGUAGUUGAUACGUCAAGACGUCGAAACGCUCAGUAGC\n",
      "........((.(((.((.((((....(((((((....))))..)))..)))))).))).)).(((.(((...((((....))))...))))))....... \u001b[93m[   0,    0 ]\u001b[0m -21.40\n",
      "........\u001b[93m\u001b[1m.\u001b[0m(.(((.((.((((....(((((((....))))..)))..)))))).))).)\u001b[93m\u001b[1m.\u001b[0m.(((.(((...((((....))))...))))))....... \u001b[93m[  -9,  -61 ]\u001b[0m -21.00\n",
      ".........\u001b[93m\u001b[1m.\u001b[0m.(((.((.((((....(((((((....))))..)))..)))))).))).\u001b[93m\u001b[1m.\u001b[0m..(((.(((...((((....))))...))))))....... \u001b[93m[ -10,  -60 ]\u001b[0m -21.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))....\u001b[93m\u001b[1m.\u001b[0m((.(((...((((....))))...)))))\u001b[93m\u001b[1m.\u001b[0m....... \u001b[93m[ -63,  -93 ]\u001b[0m -19.90\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....(\u001b[93m\u001b[1m.\u001b[0m.(((...((((....))))...)))\u001b[93m\u001b[1m.\u001b[0m)........ \u001b[93m[ -65,  -91 ]\u001b[0m -18.70\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....\u001b[93m\u001b[1m.\u001b[0m..(((...((((....))))...))).\u001b[93m\u001b[1m.\u001b[0m........ \u001b[93m[ -64,  -92 ]\u001b[0m -20.20\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........(((...(((\u001b[93m\u001b[1m.\u001b[0m....\u001b[93m\u001b[1m.\u001b[0m)))...))).......... \u001b[93m[ -76,  -81 ]\u001b[0m -19.10\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........((\u001b[93m\u001b[1m.\u001b[0m...(((......)))...\u001b[93m\u001b[1m.\u001b[0m)).......... \u001b[93m[ -69,  -88 ]\u001b[0m -16.90\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........((....\u001b[93m\u001b[1m.\u001b[0m((......))\u001b[93m\u001b[1m.\u001b[0m....)).......... \u001b[93m[ -73,  -84 ]\u001b[0m -15.20\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........(\u001b[93m\u001b[1m.\u001b[0m.....((......)).....\u001b[93m\u001b[1m.\u001b[0m).......... \u001b[93m[ -68,  -89 ]\u001b[0m -13.50\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........\u001b[93m\u001b[1m.\u001b[0m......((......))......\u001b[93m\u001b[1m.\u001b[0m.......... \u001b[93m[ -67,  -90 ]\u001b[0m -15.90\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))...............(\u001b[93m\u001b[1m.\u001b[0m......\u001b[93m\u001b[1m.\u001b[0m)................. \u001b[93m[ -75,  -82 ]\u001b[0m -13.80\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))...............\u001b[93m\u001b[1m.\u001b[0m........\u001b[93m\u001b[1m.\u001b[0m................. \u001b[93m[ -74,  -83 ]\u001b[0m -16.70\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........\u001b[93m\u001b[1m(\u001b[0m......\u001b[93m\u001b[1m)\u001b[0m.......................... \u001b[93m[  67,   74 ]\u001b[0m -13.80\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........(\u001b[93m\u001b[1m(\u001b[0m....\u001b[93m\u001b[1m)\u001b[0m).......................... \u001b[93m[  68,   73 ]\u001b[0m -15.60\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))\u001b[93m\u001b[1m(\u001b[0m.......((....)).......\u001b[93m\u001b[1m)\u001b[0m.................. \u001b[93m[  59,   82 ]\u001b[0m -13.80\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))(\u001b[93m\u001b[1m(\u001b[0m......((....))......\u001b[93m\u001b[1m)\u001b[0m).................. \u001b[93m[  60,   81 ]\u001b[0m -15.50\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))((\u001b[93m\u001b[1m(\u001b[0m.....((....)).....\u001b[93m\u001b[1m)\u001b[0m)).................. \u001b[93m[  61,   80 ]\u001b[0m -17.00\n",
      "...........(((.\u001b[93m\u001b[1m.\u001b[0m(.((((....(((((((....))))..)))..)))))\u001b[93m\u001b[1m.\u001b[0m.)))(((.....((....)).....))).................. \u001b[93m[ -16,  -54 ]\u001b[0m -14.70\n",
      "...........(((..(.((((....(((((((....))))..)))..)))))..)))(((\u001b[93m\u001b[1m(\u001b[0m....((....))....\u001b[93m\u001b[1m)\u001b[0m))).................. \u001b[93m[  62,   79 ]\u001b[0m -15.50\n",
      "...........(((..(.((((....\u001b[93m\u001b[1m.\u001b[0m((((((....))))..))\u001b[93m\u001b[1m.\u001b[0m..)))))..)))((((....((....))....)))).................. \u001b[93m[ -27,  -46 ]\u001b[0m -13.80\n",
      "...........(((..\u001b[93m\u001b[1m.\u001b[0m.((((.....((((((....))))..))...))))\u001b[93m\u001b[1m.\u001b[0m..)))((((....((....))....)))).................. \u001b[93m[ -17,  -53 ]\u001b[0m -13.20\n",
      "...........(((....((((.....(\u001b[93m\u001b[1m.\u001b[0m((((....))))..\u001b[93m\u001b[1m.\u001b[0m)...))))...)))((((....((....))....)))).................. \u001b[93m[ -29,  -44 ]\u001b[0m -10.30\n",
      "...........(((....((((.....\u001b[93m\u001b[1m.\u001b[0m.((((....))))...\u001b[93m\u001b[1m.\u001b[0m...))))...)))((((....((....))....)))).................. \u001b[93m[ -28,  -45 ]\u001b[0m -13.20\n",
      "...........(((....((((.....\u001b[93m\u001b[1m(\u001b[0m.((((....)))).\u001b[93m\u001b[1m)\u001b[0m.....))))...)))((((....((....))....)))).................. \u001b[93m[  28,   43 ]\u001b[0m -15.00\n",
      "...........\u001b[93m\u001b[1m.\u001b[0m((....((((.....(.((((....)))).).....))))...))\u001b[93m\u001b[1m.\u001b[0m((((....((....))....)))).................. \u001b[93m[ -12,  -58 ]\u001b[0m -11.10\n",
      "............((....((((.....(.((((....)))).).....))))...))\u001b[93m\u001b[1m(\u001b[0m((((....((....))....))))\u001b[93m\u001b[1m)\u001b[0m................. \u001b[93m[  58,   83 ]\u001b[0m -13.10\n",
      "............\u001b[93m\u001b[1m.\u001b[0m(....((((.....(.((((....)))).).....))))...)\u001b[93m\u001b[1m.\u001b[0m(((((....((....))....)))))................. \u001b[93m[ -13,  -57 ]\u001b[0m -10.20\n",
      ".............\u001b[93m\u001b[1m.\u001b[0m....((((.....(.((((....)))).).....))))...\u001b[93m\u001b[1m.\u001b[0m.(((((....((....))....)))))................. \u001b[93m[ -14,  -56 ]\u001b[0m -12.40\n",
      "..................((((.....(.((((....)))).).....))))...\u001b[93m\u001b[1m(\u001b[0m.(((((....((....))....))))).\u001b[93m\u001b[1m)\u001b[0m............... \u001b[93m[  56,   85 ]\u001b[0m -12.30\n",
      "..................((((.....(.((((....)))).).....))))..\u001b[93m\u001b[1m(\u001b[0m(.(((((....((....))....))))).)\u001b[93m\u001b[1m)\u001b[0m.............. \u001b[93m[  55,   86 ]\u001b[0m -12.00\n",
      "..................((((.....(.((((....)))).).....))))..((\u001b[93m\u001b[1m(\u001b[0m(((((....((....))....)))))\u001b[93m\u001b[1m)\u001b[0m)).............. \u001b[93m[  57,   84 ]\u001b[0m -16.50\n",
      "..................\u001b[93m\u001b[1m.\u001b[0m(((.....(.((((....)))).).....)))\u001b[93m\u001b[1m.\u001b[0m..((((((((....((....))....)))))))).............. \u001b[93m[ -19,  -52 ]\u001b[0m -15.50\n",
      "...................\u001b[93m\u001b[1m.\u001b[0m((.....(.((((....)))).).....))\u001b[93m\u001b[1m.\u001b[0m...((((((((....((....))....)))))))).............. \u001b[93m[ -20,  -51 ]\u001b[0m -14.20\n",
      "....................\u001b[93m\u001b[1m.\u001b[0m(.....(.((((....)))).).....)\u001b[93m\u001b[1m.\u001b[0m....((((((((....((....))....)))))))).............. \u001b[93m[ -21,  -50 ]\u001b[0m -11.30\n",
      ".....................\u001b[93m\u001b[1m.\u001b[0m.....(.((((....)))).).....\u001b[93m\u001b[1m.\u001b[0m.....((((((((....((....))....)))))))).............. \u001b[93m[ -22,  -49 ]\u001b[0m -12.70\n",
      "...........................(.((((....)))).).........\u001b[93m\u001b[1m(\u001b[0m.((((((((....((....))....))))))))...\u001b[93m\u001b[1m)\u001b[0m.......... \u001b[93m[  53,   90 ]\u001b[0m -11.40\n",
      "...........................(.((((....)))).)........\u001b[93m\u001b[1m(\u001b[0m(.((((((((....((....))....))))))))...)\u001b[93m\u001b[1m)\u001b[0m......... \u001b[93m[  52,   91 ]\u001b[0m -11.50\n",
      "...........................(.((((....)))).)....\u001b[93m\u001b[1m(\u001b[0m...((.((((((((....((....))....))))))))...))....\u001b[93m\u001b[1m)\u001b[0m.... \u001b[93m[  48,   96 ]\u001b[0m \u001b[91m\u001b[1m-10.00\u001b[0m\n",
      "...........................(.((((....)))).)...\u001b[93m\u001b[1m(\u001b[0m(...((.((((((((....((....))....))))))))...))....)\u001b[93m\u001b[1m)\u001b[0m... \u001b[93m[  47,   97 ]\u001b[0m -11.40\n",
      "...........................(.((((....)))).).\u001b[93m\u001b[1m(\u001b[0m.((...((.((((((((....((....))....))))))))...))....)).\u001b[93m\u001b[1m)\u001b[0m. \u001b[93m[  45,   99 ]\u001b[0m -11.00\n",
      "...........................(.((((....)))).).(\u001b[93m\u001b[1m(\u001b[0m((...((.((((((((....((....))....))))))))...))....))\u001b[93m\u001b[1m)\u001b[0m). \u001b[93m[  46,   98 ]\u001b[0m -15.60\n",
      "..........\u001b[93m\u001b[1m(\u001b[0m..........\u001b[93m\u001b[1m)\u001b[0m.....(.((((....)))).).((((...((.((((((((....((....))....))))))))...))....)))). \u001b[93m[  11,   22 ]\u001b[0m -12.00\n",
      "..........(\u001b[93m\u001b[1m(\u001b[0m........\u001b[93m\u001b[1m)\u001b[0m).....(.((((....)))).).((((...((.((((((((....((....))....))))))))...))....)))). \u001b[93m[  12,   21 ]\u001b[0m -15.90\n",
      "..\u001b[93m\u001b[1m(\u001b[0m.......((........))..\u001b[93m\u001b[1m)\u001b[0m..(.((((....)))).).((((...((.((((((((....((....))....))))))))...))....)))). \u001b[93m[   3,   25 ]\u001b[0m -11.40\n",
      "..(\u001b[93m\u001b[1m(\u001b[0m......((........)).\u001b[93m\u001b[1m)\u001b[0m)..(.((((....)))).).((((...((.((((((((....((....))....))))))))...))....)))). \u001b[93m[   4,   24 ]\u001b[0m -14.20\n",
      "..((\u001b[93m\u001b[1m(\u001b[0m.....((........))\u001b[93m\u001b[1m)\u001b[0m))..(.((((....)))).).((((...((.((((((((....((....))....))))))))...))....)))). \u001b[93m[   5,   23 ]\u001b[0m -17.00\n",
      "..(((.....((........)))))..(.((((....)))).)\u001b[93m\u001b[1m(\u001b[0m((((...((.((((((((....((....))....))))))))...))....))))\u001b[93m\u001b[1m)\u001b[0m \u001b[93m[  44,  100 ]\u001b[0m -19.60\n",
      "S: -10.00 kcal/mol | B:  11.40 kcal/mol | E[start]:-21.40 E[end]:-19.60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-10.0"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_samples = f'./dataset_100.csv'\n",
    "samples_df = pd.read_csv(filename_samples)\n",
    "\n",
    "sequence = ''\n",
    "s1 = ''\n",
    "s2 = ''\n",
    "\n",
    "for index, row in samples_df.iterrows():\n",
    "    if index != 22:\n",
    "        continue\n",
    "    sequence = row.sequence\n",
    "    s1 = row.s1\n",
    "    s2 = row.s2\n",
    "\n",
    "print (sequence)\n",
    "print (s1)\n",
    "print (s2)\n",
    "\n",
    "fc = RNA.fold_compound(sequence)\n",
    "en1 = fc.eval_structure(s1)\n",
    "en2 = fc.eval_structure(s2)\n",
    "\n",
    "def fp_call_sw(sequence, s1, s2, search_width):    \n",
    "    fp = findpath.findpath_single(sequence, s1, s2, search_width=search_width, mp=True)\n",
    "    result = fp.get_en()/100.0\n",
    "    path = fp.get_path()\n",
    "    # return result, path\n",
    "    return result, path\n",
    "\n",
    "\n",
    "sw = 1\n",
    "sw = 100\n",
    "\n",
    "r, p = fp_call_sw(sequence, s1, s2, sw)\n",
    "p = [(i[0], i[1]) for i in p]\n",
    "\n",
    "print_moves(sequence, s1, s2, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = s1\n",
    "# fc = RNA.fold_compound(sequence)\n",
    "# pt = list(RNA.ptable(s))\n",
    "# pt2 = list(RNA.ptable(s2))\n",
    "\n",
    "# lasts = s\n",
    "# lasti = 0\n",
    "# lastj = 0\n",
    "# last_move = (0,0)\n",
    "\n",
    "# en_max = fc.eval_structure(s)\n",
    "\n",
    "\n",
    "# result, path = fp_call(sequence, s1, s2, 1)\n",
    "# all_moves = [(abs(i[0]), abs(i[1])) for i in path]\n",
    "\n",
    "# prev_move_dist = np.zeros((20)) \n",
    "\n",
    "# found_moves = [(0, 0)]\n",
    "\n",
    "# dist = 0\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     dist += 1\n",
    "#     # check where we can go, compare with our best move. \n",
    "#     pt = list(RNA.ptable(s))\n",
    "\n",
    "#     # check available moves, save them, sort them    \n",
    "#     avail_moves = []\n",
    "#     ij_moves = []\n",
    "#     found_pos = None\n",
    "\n",
    "    # # collect moves from the generator function, then sort them.\n",
    "    # for pos, (i,j) in enumerate(find_moves(pt, pt2)):    \n",
    "    #     next_en = fc.eval_move_pt(pt, i, j)\n",
    "    #     # mark where we found our move\n",
    "    #     found = None\n",
    "    #     avail_moves.append((i, j, next_en, found))\n",
    "    #     ij_moves.append((abs(i),abs(j)))\n",
    "\n",
    "\n",
    "    # avail_moves.sort(key=lambda x: x[2])\n",
    "    # found_list = [x[3] for x in avail_moves]\n",
    "    # en_list = np.array([[x[2] for x in avail_moves]])\n",
    "    # en_list_scaled = min_max_scaler.fit_transform(en_list.T).T[0]\n",
    "\n",
    "    # i_shift_moves, j_shift_moves = return_shift_moves(all_moves)\n",
    "\n",
    "    # # print (s, pt, avail_moves)\n",
    "    # # print (en_list_scaled)\n",
    "\n",
    "    # candidates = []\n",
    "\n",
    "    # for pos, (i,j, en, found) in enumerate(avail_moves):\n",
    "\n",
    "    #     this_move = (abs(i), abs(j))\n",
    "    #     last_move = (lasti, lastj)\n",
    "\n",
    "    #     if lasti:\n",
    "    #         # print (this_move, last_move, ij_moves)\n",
    "    #         ijd, thisclose, lastclose = ij_distance(last_move, this_move, ij_moves)\n",
    "    #     else:\n",
    "    #         ijd, thisclose, lastclose = 0, 0, 0\n",
    "\n",
    "#         cd = config_distance(pt, this_move)\n",
    "\n",
    "#         en_scaled = en_list_scaled[pos]\n",
    "\n",
    "\n",
    "#         if abs(i) in i_shift_moves:\n",
    "#             i_shift = 1\n",
    "#         else:\n",
    "#             i_shift = 0\n",
    "#         if abs(j) in j_shift_moves:\n",
    "#             j_shift = 1\n",
    "#         else:\n",
    "#             j_shift = 0\n",
    "\n",
    "#         if i<0:\n",
    "#             insert_or_delete = 0\n",
    "#         else:\n",
    "#             insert_or_delete = 1\n",
    "\n",
    "#         if i > 0:\n",
    "#             snew = s[:i-1] + \"(\" + s[i:j-1] + \")\" + s[j:]\n",
    "#         if i < 0:\n",
    "#             snew = s[:-i-1] + \".\" + s[-i:-j-1] + \".\" + s[-j:]\n",
    "#         # ptnew = list(RNA.ptable(snew))\n",
    "#         balance = balance_in_all_things(s1, s2, snew) / len(all_moves)\n",
    "\n",
    "\n",
    "#         # run the prediction\n",
    "#         sample = 1, ijd, thisclose, lastclose, cd, en_list_scaled[pos], 1\n",
    "        \n",
    "#         sample = { \"target\": 0,\n",
    "#            \"ijd\":       ijd,\n",
    "#            \"thisclose\": thisclose,\n",
    "#            \"lastclose\": lastclose,\n",
    "#            \"cd\":        cd,\n",
    "#            \"en_pos\":    en_list_scaled[pos],\n",
    "#            \"i_shift\":   i_shift, \n",
    "#            \"j_shift\":   j_shift,\n",
    "#            \"insert_or_delete\": insert_or_delete,\n",
    "#            \"balance\":   balance,\n",
    "#             \"0\":  prev_move_dist[0],\n",
    "#             \"1\":  prev_move_dist[1],\n",
    "#             \"2\":  prev_move_dist[2],\n",
    "#             \"3\":  prev_move_dist[3],\n",
    "#             \"4\":  prev_move_dist[4],\n",
    "#             \"5\":  prev_move_dist[5],\n",
    "#             \"6\":  prev_move_dist[6],\n",
    "#             \"7\":  prev_move_dist[7],\n",
    "#             \"8\":  prev_move_dist[8],\n",
    "#             \"9\":  prev_move_dist[9],\n",
    "#             \"10\":  prev_move_dist[10],\n",
    "#             \"11\":  prev_move_dist[11],\n",
    "#             \"12\":  prev_move_dist[12],\n",
    "#             \"13\":  prev_move_dist[13],\n",
    "#             \"14\":  prev_move_dist[14],\n",
    "#             \"15\":  prev_move_dist[15],\n",
    "#             \"16\":  prev_move_dist[16],\n",
    "#             \"17\":  prev_move_dist[17],\n",
    "#             \"18\":  prev_move_dist[18],\n",
    "#             \"19\":  prev_move_dist[19],\n",
    "#         }       \n",
    "        \n",
    "#         sample_test_ds = sample_to_dataset(sample, test)\n",
    "#         result_predictor = model.predict(sample_test_ds)[0][0]\n",
    "\n",
    "#         candidates.append((i, j, en_scaled, result_predictor, en))\n",
    "        \n",
    "#         # print (ijd, thisclose, lastclose, cd, en_scaled, result_predictor)\n",
    "\n",
    "\n",
    "#     # print (prev_move_dist)\n",
    "\n",
    "#     candidates.sort(key=lambda x: -x[3])\n",
    "#     # candidates.sort(key=lambda x: x[2])\n",
    "\n",
    "\n",
    "\n",
    "#     # print (candidates)\n",
    "\n",
    "#     # chosen move\n",
    "#     i = candidates[0][0]\n",
    "#     j = candidates[0][1]\n",
    "\n",
    "#     lasts = s\n",
    "#     lasti = abs(i)\n",
    "#     lastj = abs(j)\n",
    "\n",
    "#     prev_move_dist = new_move_dist(lasti, lastj, prev_move_dist)\n",
    "\n",
    "#     if i > 0:\n",
    "#         s = s[:i-1] + \"(\" + s[i:j-1] + \")\" + s[j:]\n",
    "#     if i < 0:\n",
    "#         s = s[:-i-1] + \".\" + s[-i:-j-1] + \".\" + s[-j:]\n",
    "\n",
    "#     en_new = fc.eval_structure(s)\n",
    "#     if en_new > en_max:\n",
    "#         en_max = en_new\n",
    "\n",
    "#     # print (s, i, j, en_new, en_max)\n",
    "\n",
    "#     found_moves.append((i, j))\n",
    "\n",
    "#     for i0, (i1, i2, i3, i4, i5) in enumerate(candidates):\n",
    "#         print (f' {dist:3}, {en_max:2.2}, {i0:6}, {i1:6}, {i2:6}, {i3:6.2}, {i4:6.4}, {i5:6}')\n",
    "#         if i0 == 3:\n",
    "#             break\n",
    "\n",
    "#     # break\n",
    "\n",
    "#     if s==s2:\n",
    "#         break\n",
    "\n",
    "\n",
    "# # WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'ijd': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'thisclose': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'lastclose': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'cd': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=int64>, 'en_pos': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'i_shift': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=int64>, 'j_shift': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=int64>, 'insert_or_delete': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=int64>, 'balance': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, '0': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, '1': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, '2': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, '3': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, '4': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, '5': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, '6': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, '7': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, '8': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, '9': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, '10': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, '11': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, '12': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, '13': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, '14': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, '15': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, '16': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, '17': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, '18': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, '19': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>}\n",
    "# Consider rewriting this model with the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCUUUGGAUUUCCGGGCCAUUAACGCACCCCGUCUAGUAUCCCACUAUGGCAAGCUAACUUAAAGGUCUAGAAAGCCGAACCAGCUCCCGUCUAGACCGU\n",
      "((((.((....))(((............)))(((((((.....)))).))))))).........((((((((....(......)......)))))))).. \u001b[93m[   0,    0 ]\u001b[0m -19.30\n",
      "((((.((....))(((............)))(((((((.....)))).))))))).........((((((((....\u001b[93m\u001b[1m.\u001b[0m......\u001b[93m\u001b[1m.\u001b[0m......)))))))).. \u001b[93m[ -77,  -84 ]\u001b[0m -19.20\n",
      "((((.((....))(((............)))(((((((.....)))).))))))).........((((((((...\u001b[93m\u001b[1m(\u001b[0m.......\u001b[93m\u001b[1m)\u001b[0m......)))))))).. \u001b[93m[  76,   84 ]\u001b[0m -16.90\n",
      "((((.((....))(((............)))(((((((.....)))).))))))).........((((((((..\u001b[93m\u001b[1m(\u001b[0m(.......)\u001b[93m\u001b[1m)\u001b[0m.....)))))))).. \u001b[93m[  75,   85 ]\u001b[0m -20.60\n",
      "((((.((....))(((............)))(((((((.....)))).))))))).........((((((((.\u001b[93m\u001b[1m(\u001b[0m((.......))\u001b[93m\u001b[1m)\u001b[0m....)))))))).. \u001b[93m[  74,   86 ]\u001b[0m -21.30\n",
      "((((.((....))(((............)))(\u001b[93m\u001b[1m.\u001b[0m(((((.....)))).)\u001b[93m\u001b[1m.\u001b[0m))))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -33,  -50 ]\u001b[0m -16.80\n",
      "((((.((....))(((............)))\u001b[93m\u001b[1m.\u001b[0m.(((((.....)))).).\u001b[93m\u001b[1m.\u001b[0m)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -32,  -51 ]\u001b[0m -17.30\n",
      "((((.((....))(((............)))..\u001b[93m\u001b[1m.\u001b[0m((((.....)))).\u001b[93m\u001b[1m.\u001b[0m..)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -34,  -49 ]\u001b[0m -17.80\n",
      "((((.((....))((\u001b[93m\u001b[1m.\u001b[0m............\u001b[93m\u001b[1m.\u001b[0m))...((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -16,  -29 ]\u001b[0m -15.10\n",
      "((((.((....))(\u001b[93m\u001b[1m.\u001b[0m..............\u001b[93m\u001b[1m.\u001b[0m)...((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -15,  -30 ]\u001b[0m -11.70\n",
      "((((.((....))\u001b[93m\u001b[1m.\u001b[0m................\u001b[93m\u001b[1m.\u001b[0m...((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[ -14,  -31 ]\u001b[0m -14.80\n",
      "((((.((....))..........\u001b[93m\u001b[1m(\u001b[0m.......\u001b[93m\u001b[1m)\u001b[0m..((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  24,   32 ]\u001b[0m -12.30\n",
      "((((.((....))..........(\u001b[93m\u001b[1m(\u001b[0m.....\u001b[93m\u001b[1m)\u001b[0m)..((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  25,   31 ]\u001b[0m -14.20\n",
      "((((.((....)).........\u001b[93m\u001b[1m(\u001b[0m((.....))\u001b[93m\u001b[1m)\u001b[0m.((((.....))))....)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  23,   33 ]\u001b[0m -15.50\n",
      "((((.((....))....\u001b[93m\u001b[1m(\u001b[0m....(((.....))).((((.....)))).\u001b[93m\u001b[1m)\u001b[0m..)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  18,   49 ]\u001b[0m \u001b[91m\u001b[1m-11.00\u001b[0m\n",
      "((((.((....))...\u001b[93m\u001b[1m(\u001b[0m(....(((.....))).((((.....)))).)\u001b[93m\u001b[1m)\u001b[0m.)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  17,   50 ]\u001b[0m -13.90\n",
      "((((.((....))..\u001b[93m\u001b[1m(\u001b[0m((....(((.....))).((((.....)))).))\u001b[93m\u001b[1m)\u001b[0m)))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  16,   51 ]\u001b[0m -17.60\n",
      "((((.((....))..(((\u001b[93m\u001b[1m(\u001b[0m...(((.....))).((((.....))))\u001b[93m\u001b[1m)\u001b[0m))))))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  19,   48 ]\u001b[0m -18.30\n",
      "((((.(\u001b[93m\u001b[1m.\u001b[0m....\u001b[93m\u001b[1m.\u001b[0m)..((((...(((.....))).((((.....)))))))))))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  -7,  -12 ]\u001b[0m -15.20\n",
      "((((.\u001b[93m\u001b[1m.\u001b[0m......\u001b[93m\u001b[1m.\u001b[0m..((((...(((.....))).((((.....)))))))))))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  -6,  -13 ]\u001b[0m -17.20\n",
      "(((\u001b[93m\u001b[1m.\u001b[0m...........((((...(((.....))).((((.....))))))))\u001b[93m\u001b[1m.\u001b[0m))).........((((((((.(((.......)))....)))))))).. \u001b[93m[  -4,  -52 ]\u001b[0m -15.30\n",
      "((\u001b[93m\u001b[1m.\u001b[0m............((((...(((.....))).((((.....)))))))).\u001b[93m\u001b[1m.\u001b[0m)).........((((((((.(((.......)))....)))))))).. \u001b[93m[  -3,  -53 ]\u001b[0m -14.60\n",
      "(\u001b[93m\u001b[1m.\u001b[0m.............((((...(((.....))).((((.....))))))))..\u001b[93m\u001b[1m.\u001b[0m).........((((((((.(((.......)))....)))))))).. \u001b[93m[  -2,  -54 ]\u001b[0m \u001b[91m\u001b[1m-11.00\u001b[0m\n",
      "\u001b[93m\u001b[1m.\u001b[0m..............((((...(((.....))).((((.....))))))))...\u001b[93m\u001b[1m.\u001b[0m.........((((((((.(((.......)))....)))))))).. \u001b[93m[  -1,  -55 ]\u001b[0m -16.50\n",
      "......\u001b[93m\u001b[1m(\u001b[0m........((((...(((.....))).((((.....))))))))...\u001b[93m\u001b[1m)\u001b[0m.........((((((((.(((.......)))....)))))))).. \u001b[93m[   7,   55 ]\u001b[0m -12.10\n",
      ".....\u001b[93m\u001b[1m(\u001b[0m(........((((...(((.....))).((((.....))))))))...)\u001b[93m\u001b[1m)\u001b[0m........((((((((.(((.......)))....)))))))).. \u001b[93m[   6,   56 ]\u001b[0m -13.50\n",
      "....\u001b[93m\u001b[1m(\u001b[0m((........((((...(((.....))).((((.....))))))))...))\u001b[93m\u001b[1m)\u001b[0m.......((((((((.(((.......)))....)))))))).. \u001b[93m[   5,   57 ]\u001b[0m -14.70\n",
      "...\u001b[93m\u001b[1m(\u001b[0m(((........((((...(((.....))).((((.....))))))))...)))\u001b[93m\u001b[1m)\u001b[0m......((((((((.(((.......)))....)))))))).. \u001b[93m[   4,   58 ]\u001b[0m -15.30\n",
      "...((((.\u001b[93m\u001b[1m(\u001b[0m......((((...(((.....))).((((.....))))))))..\u001b[93m\u001b[1m)\u001b[0m))))......((((((((.(((.......)))....)))))))).. \u001b[93m[   9,   54 ]\u001b[0m -13.40\n",
      "...((((.(\u001b[93m\u001b[1m(\u001b[0m.....((((...(((.....))).((((.....)))))))).\u001b[93m\u001b[1m)\u001b[0m)))))......((((((((.(((.......)))....)))))))).. \u001b[93m[  10,   53 ]\u001b[0m -13.50\n",
      "...((((.((\u001b[93m\u001b[1m(\u001b[0m....((((...(((.....))).((((.....))))))))\u001b[93m\u001b[1m)\u001b[0m))))))......((((((((.(((.......)))....)))))))).. \u001b[93m[  11,   52 ]\u001b[0m -15.40\n",
      "S: -11.00 kcal/mol | B:   8.30 kcal/mol | E[start]:-19.30 E[end]:-15.40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-11.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_moves(sequence, s1, s2, found_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: optimal path, compare with greedy & ML choice\n",
    "\n",
    "# check positions: at which position did we find the best move in our move set? \n",
    "\n",
    "\n",
    "# function needs: sequence, s1, s2, lasts, currents\n",
    "\n",
    "def next_moves(sequence, s1, s2, lastmove, s, prev_move_dist = np.zeros((20))):\n",
    "\n",
    "    # first do a basic findpath call with minimal search width to get all moves (simple, but expensive)\n",
    "\n",
    "    search_width_multiplier = 20\n",
    "    result, path = fp_call(sequence, s1, s2, search_width_multiplier)\n",
    "  \n",
    "\n",
    "    all_moves = [(abs(i[0]), abs(i[1])) for i in path]\n",
    "    i_shift_moves, j_shift_moves = return_shift_moves(all_moves)\n",
    "      \n",
    "\n",
    "    prev_move_dist = new_move_dist(lastmove[0], lastmove[1], prev_move_dist)\n",
    "\n",
    "    # print (all_moves, i_shift_moves, prev_move_dist)\n",
    "    \n",
    "    fc = RNA.fold_compound(sequence)\n",
    "    pt = list(RNA.ptable(s))\n",
    "    pt2 = list(RNA.ptable(s2))\n",
    "\n",
    "    # check available moves based on our current structure\n",
    "    avail_moves = []\n",
    "    ij_moves = []\n",
    "    found_pos = None\n",
    "\n",
    "    for pos, (i,j) in enumerate(find_moves(pt, pt2)):    \n",
    "        next_en = fc.eval_move_pt(pt, i, j)\n",
    "        # mark where we found our move\n",
    "        avail_moves.append((i, j, next_en))\n",
    "        ij_moves.append((abs(i),abs(j)))\n",
    "\n",
    "    # sort moves independent of delete insert moves\n",
    "    ij_moves.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    avail_moves.sort(key=lambda x: x[2])\n",
    "\n",
    "    # sort avail moves by energy\n",
    "    en_list = np.array([[x[2] for x in avail_moves]])\n",
    "    en_list_scaled = min_max_scaler.fit_transform(en_list.T).T[0] # best en gets 0, worst = 1\n",
    "\n",
    "    for pos, (i,j, en) in enumerate(avail_moves):           \n",
    "\n",
    "        en_scaled = en_list_scaled[pos]\n",
    "\n",
    "        if i > 0:\n",
    "            snew = s[:i-1] + \"(\" + s[i:j-1] + \")\" + s[j:]\n",
    "        if i < 0:\n",
    "            snew = s[:-i-1] + \".\" + s[-i:-j-1] + \".\" + s[-j:]\n",
    "        ptnew = list(RNA.ptable(snew))\n",
    "        \n",
    "\n",
    "        thismove = (abs(i), abs(j))\n",
    "\n",
    "        # generate features\n",
    "        if lasti:\n",
    "            # print (this_move, last_move, ij_moves)\n",
    "            ijd, thisclose, lastclose = ij_distance(lastmove, thismove, ij_moves)\n",
    "        else:\n",
    "            ijd, thisclose, lastclose = 0, 0, 0\n",
    "        cd = config_distance(pt, thismove)            \n",
    "        if abs(i) in i_shift_moves:\n",
    "            i_shift = 1\n",
    "        else:\n",
    "            i_shift = 0\n",
    "        if abs(j) in j_shift_moves:\n",
    "            j_shift = 1\n",
    "        else:\n",
    "            j_shift = 0\n",
    "        if i<0:\n",
    "            insert_or_delete = 0\n",
    "        else:\n",
    "            insert_or_delete = 1\n",
    "        balance = balance_in_all_things(s1, s2, snew) / len(all_moves)\n",
    "\n",
    "        # compare our prediction with true labels: compute findpath with all next s:        \n",
    "\n",
    "        result_new, path = fp_call(sequence, snew, s2, search_width_multiplier)   \n",
    "        en_current = fc.eval_structure(s)\n",
    "        en_max = max(result_new, en_current)\n",
    "\n",
    "        # if our energy is lower or equal to the overall findpath call, then this i,j move gets the true label 1. \n",
    "        if en_max <= result:\n",
    "            en_max = 1\n",
    "        else:\n",
    "            en_max = 0\n",
    "\n",
    "        en_max = result_new\n",
    "\n",
    "        # print ('overall fp:', result, 'fp result from snew', result_new, 'en max', max(result_new, en_current), en_max)\n",
    "\n",
    "        # result_new = \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return_vals = [snew, i, j, en_max, ijd, thisclose, lastclose, cd, en_scaled, i_shift, j_shift, insert_or_delete, balance] + list(prev_move_dist)\n",
    "\n",
    "        yield return_vals\n",
    "        # print (i, j, en_scaled, result_new, balance, insert_or_delete, cd)\n",
    "\n",
    "    # print (avail_moves, en_list_scaled)\n",
    "    # print (prev_move_dist)\n",
    "    \n",
    "\n",
    "\n",
    "# sequence = \"GCUUUGGAUUUCCGGGCCAUUAACGCACCCCGUCUAGUAUCCCACUAUGGCAAGCUAACUUAAAGGUCUAGAAAGCCGAACCAGCUCCCGUCUAGACCGU\"\n",
    "# s1       = \"((((.((....))(((............)))(((((((.....)))).))))))).........((((((((....(......)......))))))))..\"\n",
    "# s2       = \"...((((.(((....((((...(((.....))).((((.....)))))))))))))))......((((((((.(((.......)))....))))))))..\"\n",
    "# lastmove = [  25,   31 ]\n",
    "# s        = \"((((.((....)).........(((.....))).((((.....))))....)))).........((((((((.(((.......)))....))))))))..\"\n",
    "\n",
    "sequence = \"ACGGUAUCGGGGCCCUCCAACCACCAAGCGGCAGGAUUGCCACGCUACGGUUGAUGGCGUUUAGUAGUUGAUACGUCAAGACGUCGAAACGCUCAGUAGC\"\n",
    "s1       = \"........((.(((.((.((((....(((((((....))))..)))..)))))).))).)).(((.(((...((((....))))...)))))).......\"\n",
    "s2       = \"..(((.....((........)))))..(.((((....)))).)(((((...((.((((((((....((....))....))))))))...))....)))))\"\n",
    "s = s1\n",
    "lastmove = (0,0)\n",
    "\n",
    "def predict_next_moves(sequence, s1, s2, lastmove, s, prev_move_dist):\n",
    "    results = []\n",
    "    for vals in next_moves(sequence, s1, s2, lastmove, s, prev_move_dist):\n",
    "        results.append(vals)\n",
    "\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_df.columns = ['s', 'i', 'j', 'target', 'ijd', 'thisclose', 'lastclose', 'cd', 'en_pos',\\\n",
    "                        'i_shift', 'j_shift', 'insert_or_delete', 'balance',\\\n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\\\n",
    "                        '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
    "\n",
    "    # def sample1_to_dataset(test):\n",
    "    #   sample_test = test.iloc[0:5].copy()\n",
    "    #   sample_test_ds = df_to_dataset(sample_test, shuffle=False, batch_size=batch_size)\n",
    "    #   return sample_test_ds\n",
    "    # batch_prediction = sample1_to_dataset(test)\n",
    "    # print (batch_prediction)\n",
    "\n",
    "    batch_prediction = df_to_dataset(output_df, shuffle=False, batch_size=batch_size)\n",
    "    result_predictor = model.predict(batch_prediction)\n",
    "\n",
    "    output_df[\"prediction\"] = result_predictor\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "prev_move_dist = np.zeros((20))\n",
    "pred_df = predict_next_moves(sequence, s1, s2, lastmove, s, prev_move_dist)\n",
    "# pred_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move along a good path, compare results with our predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen i -9 j -61 choice: 0 out of 24 or 0 out of 24\n",
      "Chosen i -10 j -60 choice: 0 out of 23 or 0 out of 23\n",
      "Chosen i -76 j -81 choice: 18 out of 22 or 1 out of 22\n",
      "Chosen i -63 j -93 choice: 17 out of 21 or 0 out of 21\n",
      "Chosen i -74 j -83 choice: 16 out of 20 or 0 out of 20\n",
      "Chosen i -65 j -91 choice: 2 out of 19 or 0 out of 19\n",
      "Chosen i -75 j -82 choice: 2 out of 18 or 0 out of 18\n",
      "Chosen i -73 j -84 choice: 0 out of 17 or 0 out of 17\n",
      "Chosen i -64 j -92 choice: 0 out of 16 or 0 out of 16\n",
      "Chosen i -69 j -88 choice: 2 out of 15 or 2 out of 15\n",
      "Chosen i -68 j -89 choice: 2 out of 14 or 2 out of 14\n",
      "Chosen i -67 j -90 choice: 0 out of 14 or 0 out of 14\n",
      "Chosen i -19 j -52 choice: 6 out of 18 or 0 out of 18\n",
      "Chosen i 67 j 74 choice: 5 out of 17 or 5 out of 17\n",
      "Chosen i 68 j 73 choice: 0 out of 16 or 0 out of 16\n",
      "Chosen i 59 j 82 choice: 0 out of 15 or 0 out of 15\n",
      "Chosen i 60 j 81 choice: 0 out of 14 or 0 out of 14\n",
      "Chosen i 61 j 80 choice: 0 out of 13 or 0 out of 13\n",
      "Chosen i 62 j 79 choice: 0 out of 12 or 0 out of 12\n",
      "Chosen i -12 j -58 choice: 7 out of 11 or 7 out of 11\n",
      "Chosen i 58 j 83 choice: 0 out of 11 or 0 out of 11\n",
      "Chosen i -13 j -57 choice: 9 out of 10 or 9 out of 10\n",
      "Chosen i 57 j 84 choice: 1 out of 10 or 0 out of 10\n",
      "Chosen i -14 j -56 choice: 3 out of 9 or 3 out of 9\n",
      "Chosen i 56 j 85 choice: 0 out of 10 or 0 out of 10\n",
      "Chosen i -16 j -54 choice: 5 out of 9 or 3 out of 9\n",
      "Chosen i -17 j -53 choice: 0 out of 8 or 0 out of 8\n",
      "Chosen i -20 j -51 choice: 1 out of 9 or 1 out of 9\n",
      "Chosen i -21 j -50 choice: 1 out of 8 or 1 out of 8\n",
      "Chosen i -22 j -49 choice: 0 out of 8 or 0 out of 8\n",
      "Chosen i 12 j 21 choice: 2 out of 13 or 2 out of 13\n",
      "Chosen i 11 j 22 choice: 0 out of 12 or 0 out of 12\n",
      "Chosen i 3 j 25 choice: 6 out of 11 or 1 out of 11\n",
      "Chosen i 4 j 24 choice: 0 out of 10 or 0 out of 10\n",
      "Chosen i 5 j 23 choice: 0 out of 9 or 0 out of 9\n",
      "Chosen i -27 j -46 choice: 1 out of 8 or 1 out of 8\n",
      "Chosen i -29 j -44 choice: 3 out of 8 or 3 out of 8\n",
      "Chosen i -28 j -45 choice: 3 out of 7 or 3 out of 7\n",
      "Chosen i 28 j 43 choice: 1 out of 9 or 0 out of 9\n",
      "Chosen i 55 j 86 choice: 0 out of 8 or 0 out of 8\n",
      "Chosen i 53 j 90 choice: 0 out of 7 or 0 out of 7\n",
      "Chosen i 52 j 91 choice: 0 out of 6 or 0 out of 6\n",
      "Chosen i 48 j 96 choice: 0 out of 5 or 0 out of 5\n",
      "Chosen i 47 j 97 choice: 0 out of 4 or 0 out of 4\n",
      "Chosen i 46 j 98 choice: 0 out of 3 or 0 out of 3\n",
      "Chosen i 45 j 99 choice: 0 out of 2 or 0 out of 2\n",
      "Chosen i 44 j 100 choice: 0 out of 1 or 0 out of 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sequence = \"GCUUUGGAUUUCCGGGCCAUUAACGCACCCCGUCUAGUAUCCCACUAUGGCAAGCUAACUUAAAGGUCUAGAAAGCCGAACCAGCUCCCGUCUAGACCGU\"\n",
    "# s1       = \"((((.((....))(((............)))(((((((.....)))).))))))).........((((((((....(......)......))))))))..\"\n",
    "# s2       = \"...((((.(((....((((...(((.....))).((((.....)))))))))))))))......((((((((.(((.......)))....))))))))..\"\n",
    "\n",
    "# sequence = \"ACCGAUUGACUAAGUAUAGUUCCUUCACCGUUAUUCUGAUCGCCGGAGAGUUUUACGCGUCAUUUCCCGCUCAAACCCGCUCAUUGCUGAACGUUGAAGA\"\n",
    "# s1       = \".......(((((....))))).(((((.((((.........((.(((((.............))))).))........((.....))..)))).))))).\"\n",
    "# s2       = \".......(((((....))))).(((((.(((........(((.(((.(((((((..(((........)))..)))...)))).))).)))))).))))).\"\n",
    "\n",
    "\n",
    "search_width_multiplier = 20\n",
    "result, path = fp_call(sequence, s1, s2, search_width_multiplier)\n",
    "# print_moves(sequence, s1, s2, path)\n",
    "\n",
    "s = s1\n",
    "lasts = s1\n",
    "lastmove = (0,0)\n",
    "prev_move_dist = np.zeros((20))\n",
    "\n",
    "compare_list = []\n",
    "\n",
    "for e, (i, j, _) in enumerate(path):\n",
    "\n",
    "    if e==0: continue\n",
    "\n",
    "    # print (s, i, j)\n",
    "    # print (prev_move_dist)\n",
    "\n",
    "    predict_df = predict_next_moves(sequence, s1, s2, lastmove, s, prev_move_dist)\n",
    "\n",
    "    # print (predict_df)\n",
    "\n",
    "    # if e==3:\n",
    "    #     print (\"move\", i, j)\n",
    "    #     print (predict_df)\n",
    "\n",
    "    # if i==41:\n",
    "    #     print (predict_df)\n",
    "\n",
    "    # if we want to sort with our predictor\n",
    "    predict_df.sort_values(by=['prediction'], ascending=False, ignore_index=True, inplace=True)\n",
    "\n",
    "    choices = predict_df.shape[0]\n",
    "    pred_row = predict_df[predict_df['i'] == i]\n",
    "\n",
    "    # we have to verify here which moves actually lead to the optimal result! \n",
    "    # alternatively: find the first row with target==1:\n",
    "    # we don't exactly have to hit the same i,j but a move which leads to the same optimal result\n",
    "\n",
    "\n",
    "    # print (predict_df[['i', 'j', 'target', 'en_pos', 'prediction']].head())\n",
    "\n",
    "\n",
    "    # compare = predict_df[predict_df['target'] == 1].index.values[0]\n",
    "    best_en = predict_df['target'].min()\n",
    "    compare = predict_df[predict_df['target'] == best_en].index.values[0]\n",
    "\n",
    "    compare_list.append(compare/choices)\n",
    "\n",
    "    # print (predict_df[predict_df['target'] == 1])\n",
    "\n",
    "    # print (pred_row)\n",
    "    print ('Chosen i', i, 'j', j, 'choice:', pred_row.index.values[0], 'out of', choices, 'or', compare, 'out of', choices)\n",
    "\n",
    "\n",
    "    # update s with our predefined move\n",
    "    lasts = s\n",
    "    lastmove = (abs(i), abs(j))\n",
    "\n",
    "    prev_move_dist = new_move_dist(lastmove[0], lastmove[1], prev_move_dist)\n",
    "\n",
    "    if i > 0:\n",
    "        s = s[:i-1] + \"(\" + s[i:j-1] + \")\" + s[j:]\n",
    "    if j < 0:\n",
    "        s = s[:-i-1] + \".\" + s[-i:-j-1] + \".\" + s[-j:]\n",
    "\n",
    "\n",
    "\n",
    "    # break\n",
    "\n",
    "    # if e>=10: \n",
    "    #     break\n",
    "\n",
    "    # if e==3: \n",
    "    #     break\n",
    "\n",
    "    # if e==5:        \n",
    "    #     print (predict_df)\n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGGUAUCGGGGCCCUCCAACCACCAAGCGGCAGGAUUGCCACGCUACGGUUGAUGGCGUUUAGUAGUUGAUACGUCAAGACGUCGAAACGCUCAGUAGC\n",
      "........((.(((.((.((((....(((((((....))))..)))..)))))).))).)).(((.(((...((((....))))...))))))....... \u001b[93m[   0,    0 ]\u001b[0m -2140.00\n",
      "........\u001b[93m\u001b[1m.\u001b[0m(.(((.((.((((....(((((((....))))..)))..)))))).))).)\u001b[93m\u001b[1m.\u001b[0m.(((.(((...((((....))))...))))))....... \u001b[93m[  -9,  -61 ]\u001b[0m -2100.00\n",
      ".........\u001b[93m\u001b[1m.\u001b[0m.(((.((.((((....(((((((....))))..)))..)))))).))).\u001b[93m\u001b[1m.\u001b[0m..(((.(((...((((....))))...))))))....... \u001b[93m[ -10,  -60 ]\u001b[0m -2100.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))....(((.(((...(((\u001b[93m\u001b[1m.\u001b[0m....\u001b[93m\u001b[1m.\u001b[0m)))...))))))....... \u001b[93m[ -76,  -81 ]\u001b[0m -1990.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))....\u001b[93m\u001b[1m.\u001b[0m((.(((...(((......)))...)))))\u001b[93m\u001b[1m.\u001b[0m....... \u001b[93m[ -63,  -93 ]\u001b[0m -1880.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....((.(((...(\u001b[93m\u001b[1m.\u001b[0m(......)\u001b[93m\u001b[1m.\u001b[0m)...)))))........ \u001b[93m[ -74,  -83 ]\u001b[0m -1300.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....(\u001b[93m\u001b[1m.\u001b[0m.(((...(.(......).)...)))\u001b[93m\u001b[1m.\u001b[0m)........ \u001b[93m[ -65,  -91 ]\u001b[0m -1180.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....(..(((...(.\u001b[93m\u001b[1m.\u001b[0m......\u001b[93m\u001b[1m.\u001b[0m.)...))).)........ \u001b[93m[ -75,  -82 ]\u001b[0m -1090.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....(..(((...\u001b[93m\u001b[1m.\u001b[0m..........\u001b[93m\u001b[1m.\u001b[0m...))).)........ \u001b[93m[ -73,  -84 ]\u001b[0m -1410.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).))).....\u001b[93m\u001b[1m.\u001b[0m..(((..................))).\u001b[93m\u001b[1m.\u001b[0m........ \u001b[93m[ -64,  -92 ]\u001b[0m -1560.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........((\u001b[93m\u001b[1m.\u001b[0m..................\u001b[93m\u001b[1m.\u001b[0m)).......... \u001b[93m[ -69,  -88 ]\u001b[0m -1330.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........(\u001b[93m\u001b[1m.\u001b[0m....................\u001b[93m\u001b[1m.\u001b[0m).......... \u001b[93m[ -68,  -89 ]\u001b[0m -1190.00\n",
      "...........(((.((.((((....(((((((....))))..)))..)))))).)))........\u001b[93m\u001b[1m.\u001b[0m......................\u001b[93m\u001b[1m.\u001b[0m.......... \u001b[93m[ -67,  -90 ]\u001b[0m -1670.00\n",
      "...........(((.((.\u001b[93m\u001b[1m.\u001b[0m(((....(((((((....))))..)))..)))\u001b[93m\u001b[1m.\u001b[0m)).))).......................................... \u001b[93m[ -19,  -52 ]\u001b[0m -1450.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))........\u001b[93m\u001b[1m(\u001b[0m......\u001b[93m\u001b[1m)\u001b[0m.......................... \u001b[93m[  67,   74 ]\u001b[0m -1160.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))........(\u001b[93m\u001b[1m(\u001b[0m....\u001b[93m\u001b[1m)\u001b[0m).......................... \u001b[93m[  68,   73 ]\u001b[0m -1340.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))\u001b[93m\u001b[1m(\u001b[0m.......((....)).......\u001b[93m\u001b[1m)\u001b[0m.................. \u001b[93m[  59,   82 ]\u001b[0m -1160.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))(\u001b[93m\u001b[1m(\u001b[0m......((....))......\u001b[93m\u001b[1m)\u001b[0m).................. \u001b[93m[  60,   81 ]\u001b[0m -1330.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))((\u001b[93m\u001b[1m(\u001b[0m.....((....)).....\u001b[93m\u001b[1m)\u001b[0m)).................. \u001b[93m[  61,   80 ]\u001b[0m -1480.00\n",
      "...........(((.((..(((....(((((((....))))..)))..))).)).)))(((\u001b[93m\u001b[1m(\u001b[0m....((....))....\u001b[93m\u001b[1m)\u001b[0m))).................. \u001b[93m[  62,   79 ]\u001b[0m -1560.00\n",
      "...........\u001b[93m\u001b[1m.\u001b[0m((.((..(((....(((((((....))))..)))..))).)).))\u001b[93m\u001b[1m.\u001b[0m((((....((....))....)))).................. \u001b[93m[ -12,  -58 ]\u001b[0m -1170.00\n",
      "............((.((..(((....(((((((....))))..)))..))).)).))\u001b[93m\u001b[1m(\u001b[0m((((....((....))....))))\u001b[93m\u001b[1m)\u001b[0m................. \u001b[93m[  58,   83 ]\u001b[0m -1370.00\n",
      "............\u001b[93m\u001b[1m.\u001b[0m(.((..(((....(((((((....))))..)))..))).)).)\u001b[93m\u001b[1m.\u001b[0m(((((....((....))....)))))................. \u001b[93m[ -13,  -57 ]\u001b[0m -1080.00\n",
      ".............(.((..(((....(((((((....))))..)))..))).)).)\u001b[93m\u001b[1m(\u001b[0m(((((....((....))....)))))\u001b[93m\u001b[1m)\u001b[0m................ \u001b[93m[  57,   84 ]\u001b[0m -1240.00\n",
      ".............\u001b[93m\u001b[1m.\u001b[0m.((..(((....(((((((....))))..)))..))).)).\u001b[93m\u001b[1m.\u001b[0m((((((....((....))....))))))................ \u001b[93m[ -14,  -56 ]\u001b[0m -1240.00\n",
      "...............((..(((....(((((((....))))..)))..))).)).\u001b[93m\u001b[1m(\u001b[0m((((((....((....))....))))))\u001b[93m\u001b[1m)\u001b[0m............... \u001b[93m[  56,   85 ]\u001b[0m -1520.00\n",
      "...............\u001b[93m\u001b[1m.\u001b[0m(..(((....(((((((....))))..)))..))).)\u001b[93m\u001b[1m.\u001b[0m.(((((((....((....))....)))))))............... \u001b[93m[ -16,  -54 ]\u001b[0m -1400.00\n",
      "................\u001b[93m\u001b[1m.\u001b[0m..(((....(((((((....))))..)))..))).\u001b[93m\u001b[1m.\u001b[0m..(((((((....((....))....)))))))............... \u001b[93m[ -17,  -53 ]\u001b[0m -1570.00\n",
      "...................\u001b[93m\u001b[1m.\u001b[0m((....(((((((....))))..)))..))\u001b[93m\u001b[1m.\u001b[0m....(((((((....((....))....)))))))............... \u001b[93m[ -20,  -51 ]\u001b[0m -1440.00\n",
      "....................\u001b[93m\u001b[1m.\u001b[0m(....(((((((....))))..)))..)\u001b[93m\u001b[1m.\u001b[0m.....(((((((....((....))....)))))))............... \u001b[93m[ -21,  -50 ]\u001b[0m -1150.00\n",
      ".....................\u001b[93m\u001b[1m.\u001b[0m....(((((((....))))..)))..\u001b[93m\u001b[1m.\u001b[0m......(((((((....((....))....)))))))............... \u001b[93m[ -22,  -49 ]\u001b[0m -1440.00\n",
      "...........\u001b[93m\u001b[1m(\u001b[0m........\u001b[93m\u001b[1m)\u001b[0m.....(((((((....))))..))).........(((((((....((....))....)))))))............... \u001b[93m[  12,   21 ]\u001b[0m -1100.00\n",
      "..........\u001b[93m\u001b[1m(\u001b[0m(........)\u001b[93m\u001b[1m)\u001b[0m....(((((((....))))..))).........(((((((....((....))....)))))))............... \u001b[93m[  11,   22 ]\u001b[0m -1470.00\n",
      "..\u001b[93m\u001b[1m(\u001b[0m.......((........))..\u001b[93m\u001b[1m)\u001b[0m.(((((((....))))..))).........(((((((....((....))....)))))))............... \u001b[93m[   3,   25 ]\u001b[0m \u001b[91m\u001b[1m-1020.00\u001b[0m\n",
      "..(\u001b[93m\u001b[1m(\u001b[0m......((........)).\u001b[93m\u001b[1m)\u001b[0m).(((((((....))))..))).........(((((((....((....))....)))))))............... \u001b[93m[   4,   24 ]\u001b[0m -1300.00\n",
      "..((\u001b[93m\u001b[1m(\u001b[0m.....((........))\u001b[93m\u001b[1m)\u001b[0m)).(((((((....))))..))).........(((((((....((....))....)))))))............... \u001b[93m[   5,   23 ]\u001b[0m -1580.00\n",
      "..(((.....((........))))).\u001b[93m\u001b[1m.\u001b[0m((((((....))))..))\u001b[93m\u001b[1m.\u001b[0m.........(((((((....((....))....)))))))............... \u001b[93m[ -27,  -46 ]\u001b[0m -1420.00\n",
      "..(((.....((........)))))..(\u001b[93m\u001b[1m.\u001b[0m((((....))))..\u001b[93m\u001b[1m.\u001b[0m)..........(((((((....((....))....)))))))............... \u001b[93m[ -29,  -44 ]\u001b[0m -1130.00\n",
      "..(((.....((........)))))..\u001b[93m\u001b[1m.\u001b[0m.((((....))))...\u001b[93m\u001b[1m.\u001b[0m..........(((((((....((....))....)))))))............... \u001b[93m[ -28,  -45 ]\u001b[0m -1410.00\n",
      "..(((.....((........)))))..\u001b[93m\u001b[1m(\u001b[0m.((((....)))).\u001b[93m\u001b[1m)\u001b[0m............(((((((....((....))....)))))))............... \u001b[93m[  28,   43 ]\u001b[0m -1440.00\n",
      "..(((.....((........)))))..(.((((....)))).)...........\u001b[93m\u001b[1m(\u001b[0m(((((((....((....))....)))))))\u001b[93m\u001b[1m)\u001b[0m.............. \u001b[93m[  55,   86 ]\u001b[0m -1410.00\n",
      "..(((.....((........)))))..(.((((....)))).).........\u001b[93m\u001b[1m(\u001b[0m.((((((((....((....))....))))))))...\u001b[93m\u001b[1m)\u001b[0m.......... \u001b[93m[  53,   90 ]\u001b[0m -1280.00\n",
      "..(((.....((........)))))..(.((((....)))).)........\u001b[93m\u001b[1m(\u001b[0m(.((((((((....((....))....))))))))...)\u001b[93m\u001b[1m)\u001b[0m......... \u001b[93m[  52,   91 ]\u001b[0m -1290.00\n",
      "..(((.....((........)))))..(.((((....)))).)....\u001b[93m\u001b[1m(\u001b[0m...((.((((((((....((....))....))))))))...))....\u001b[93m\u001b[1m)\u001b[0m.... \u001b[93m[  48,   96 ]\u001b[0m -1140.00\n",
      "..(((.....((........)))))..(.((((....)))).)...\u001b[93m\u001b[1m(\u001b[0m(...((.((((((((....((....))....))))))))...))....)\u001b[93m\u001b[1m)\u001b[0m... \u001b[93m[  47,   97 ]\u001b[0m -1280.00\n",
      "..(((.....((........)))))..(.((((....)))).)..\u001b[93m\u001b[1m(\u001b[0m((...((.((((((((....((....))....))))))))...))....))\u001b[93m\u001b[1m)\u001b[0m.. \u001b[93m[  46,   98 ]\u001b[0m -1430.00\n",
      "..(((.....((........)))))..(.((((....)))).).\u001b[93m\u001b[1m(\u001b[0m(((...((.((((((((....((....))....))))))))...))....)))\u001b[93m\u001b[1m)\u001b[0m. \u001b[93m[  45,   99 ]\u001b[0m -1700.00\n",
      "..(((.....((........)))))..(.((((....)))).)\u001b[93m\u001b[1m(\u001b[0m((((...((.((((((((....((....))....))))))))...))....))))\u001b[93m\u001b[1m)\u001b[0m \u001b[93m[  44,  100 ]\u001b[0m -1960.00\n",
      "S: -1020.00 kcal/mol | B: -998.60 kcal/mol | E[start]:-21.40 E[end]:-1960.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1020"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print (compare_list)\n",
    "# search_width_multiplier = 20\n",
    "# result, path = fp_call(sequence, s1, s2, search_width_multiplier)\n",
    "# print_moves(sequence, s1, s2, path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "y = compare_list\n",
    "x = list(range(len(y)))\n",
    "# x = ['day 1', 'day 2', 'day 3']\n",
    "\n",
    "sns.lineplot(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avail -32 -90\n",
      "avail 41 89\n",
      "avail 42 88\n",
      "avail 52 75\n",
      "avail 53 74\n",
      "avail 54 73\n",
      "avail 57 70\n",
      "avail 58 69\n",
      "avail 59 68\n",
      "avail -79 -87\n",
      "avail -80 -86\n"
     ]
    }
   ],
   "source": [
    "i -42 j -70 choice: 2 out of 11\n",
    "i -43 j -69 choice: 0 out of 11\n",
    "i -49 j -63 choice: 1 out of 10\n",
    "i -48 j -64 choice: 0 out of 9\n",
    "i -47 j -65 choice: 1 out of 8\n",
    "i -45 j -67 choice: 1 out of 7\n",
    "i -46 j -66 choice: 0 out of 6\n",
    "i 58 j 69 choice: 1 out of 11\n",
    "i 57 j 70 choice: 0 out of 10\n",
    "i 59 j 68 choice: 0 out of 9\n",
    "i -32 j -90 choice: 0 out of 8\n",
    "i 41 j 89 choice: 5 out of 8\n",
    "i 40 j 90 choice: 0 out of 7\n",
    "i -79 j -87 choice: 3 out of 6\n",
    "i -80 j -86 choice: 0 out of 6\n",
    "i 42 j 88 choice: 0 out of 11\n",
    "i 44 j 86 choice: 0 out of 10\n",
    "i 45 j 85 choice: 0 out of 9\n",
    "i 46 j 84 choice: 0 out of 8\n",
    "i 49 j 81 choice: 3 out of 7\n",
    "i 50 j 80 choice: 1 out of 6\n",
    "i 53 j 74 choice: 3 out of 5\n",
    "i 54 j 73 choice: 2 out of 4\n",
    "i 52 j 75 choice: 2 out of 3\n",
    "i 51 j 79 choice: 1 out of 2\n",
    "i 48 j 82 choice: 0 out of 1\n",
    "\n",
    "# print (predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
